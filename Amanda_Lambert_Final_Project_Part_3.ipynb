{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadmanMarble/GLAP/blob/main/Amanda_Lambert_Final_Project_Part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How It Works:**\n",
        "* Preprocessing: The text is preprocessed by lowercasing, removing punctuation, and filtering stopwords using NLTK.\n",
        "* Word2Vec Model: We train a Word2Vec model on the preprocessed text. In this case, a sample corpus is used, but you can use a larger dataset for better predictions.\n",
        "* Next Word Prediction: The function predict_next_word() takes a context (a string of words) and computes the mean vector of the context words. It then finds the most similar words to this vector in the Word2Vec space, which are returned as the predicted next words."
      ],
      "metadata": {
        "id": "j9sfwwJ3jq5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 hr 37 min live discussion\n",
        "# NLTK natural language tool kit, it's preinstalled in colab\n",
        "# everything is a coordinate\n",
        "#\n",
        "\n",
        "\n",
        "# Install gensim in Colab if not already installed\n",
        "!pip install gensim\n",
        "\n",
        "# Import necessary libraries\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Download the necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "bcdjTcysj9Bn",
        "outputId": "d770b6fa-0831-44f2-f0c7-1bf285452c6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NO2JkagojDsl",
        "outputId": "47590bbb-b83f-47ba-f886-74a288f4353d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: 'ford reaching'\n",
            "Predicted next words: ['ford', 'reaching', 'fire']\n"
          ]
        }
      ],
      "source": [
        "# Sample training corpus (You can replace this with a larger dataset)\n",
        "# For example, you can load a text file from Google Drive or online source.\n",
        "# copy paste and replace in the tripple quotes to create a larger corpus.\n",
        "# this is the last assignment.\n",
        "# tomorrow we will discuss and do post assessment\n",
        "corpus = \"\"\"\n",
        "Strider sprang from hiding and dashed down towards the Road, leaping with a cry through the heather;\n",
        "but even before he had moved or called, the rider had reined in his horse and halted, looking up towards\n",
        "the thicket where they stood. When he saw Strider, he dismounted and ran to meet him calling out: Ai na\n",
        "vedui Dúnadan! Mae govannen!\n",
        "His speech and clear ringing voice left no doubt in their hearts: the rider was of the Elven-folk.\n",
        "Frodo looked back for a moment over his shoulder. He could no longer see his friends.\n",
        "The Riders behind were falling back: even their great steeds were no match in speed for the white elf-horse of Glorfindel.\n",
        "He looked forward again, and hope faded. There seemed no chance of reaching the Ford before he was cut off by the others\n",
        "that had lain in ambush. He could see them clearly now: they appeared to have cast aside their hoods and black cloaks,\n",
        "and they were robed in white and grey. Swords were naked in their pale hands; helms were on their heads. Their cold eyes\n",
        "glittered, and they called to him with fell voices.\n",
        "Fear now filled all Frodo’s mind. He thought no longer of his sword. No cry came from him. He shut his eyes and clung to\n",
        "the horse’s mane. The wind whistled in his ears, and the bells upon the harness rang wild and shrill. A breath of deadly\n",
        "cold pierced him like a spear, as with a last spurt, like a flash of white fire, the elf-horse speeding as if on wings,\n",
        "passed right before the face of the foremost Rider.\n",
        "Frodo heard the splash of water. It foamed about his feet. He felt the quick heave and surge as the horse left the river\n",
        "and struggled up the stony path. He was climbing the steep bank. He was across the Ford.\n",
        "\"\"\"\n",
        "\n",
        "# Preprocess the text (lowercase, remove punctuation, stopwords)\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return words\n",
        "\n",
        "# Preprocess the corpus\n",
        "preprocessed_corpus = preprocess_text(corpus)\n",
        "\n",
        "# Prepare data in the form required for Word2Vec (sentences split)\n",
        "sentences = [preprocessed_corpus]  # List of tokenized sentences\n",
        "\n",
        "# Train a Word2Vec model\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to predict the next word given a sequence of words\n",
        "def predict_next_word(model, context, top_n=3):\n",
        "    context_words = context.split()\n",
        "\n",
        "    # Check if all words in the context are in the model's vocabulary\n",
        "    if all(word in model.wv.index_to_key for word in context_words):\n",
        "        # Get the average vector of the context words\n",
        "        context_vector = np.mean([model.wv[word] for word in context_words], axis=0)\n",
        "\n",
        "        # Find the top_n most similar words to the context vector\n",
        "        similar_words = model.wv.similar_by_vector(context_vector, topn=top_n)\n",
        "        return [word for word, score in similar_words]\n",
        "    else:\n",
        "        return [\"One or more words in the context are not in the model vocabulary\"]\n",
        "\n",
        "# # Example usage: Predicting the next word for a given context\n",
        "# context = \"machine learning\"\n",
        "# # top n = 3 means to sepect 3 from the top probable words\n",
        "# predicted_words = predict_next_word(model, context, top_n=3)\n",
        "# print(f\"Context: '{context}'\")\n",
        "# print(f\"Predicted next words: {predicted_words}\")\n",
        "\n",
        "\n",
        "\n",
        "# # Example usage: Predicting the next word for a given context\n",
        "# context = \"ford reaching\"\n",
        "# # top n = 3 means to sepect 3 from the top probable words\n",
        "# predicted_words = predict_next_word(model, context, top_n=3)\n",
        "# print(f\"Context: '{context}'\")\n",
        "# print(f\"Predicted next words: {predicted_words}\")\n",
        "# # Context: 'ford reaching'\n",
        "# # Predicted next words: ['ford', 'reaching', 'quick']\n",
        "\n",
        "\n",
        "\n",
        "# Example usage: Predicting the next word for a given context\n",
        "context = \"ford reaching\"\n",
        "# top n = 3 means to sepect 3 from the top probable words\n",
        "predicted_words = predict_next_word(model, context, top_n=3)\n",
        "print(f\"Context: '{context}'\")\n",
        "print(f\"Predicted next words: {predicted_words}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assigned task:\n",
        "Create a larger training corpus, and perform next word prediction and print the predicted next words."
      ],
      "metadata": {
        "id": "pFnZTgOgkdXu"
      }
    }
  ]
}