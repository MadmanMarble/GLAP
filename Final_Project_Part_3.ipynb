{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadmanMarble/GLAP/blob/main/Final_Project_Part_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How It Works:**\n",
        "* Preprocessing: The text is preprocessed by lowercasing, removing punctuation, and filtering stopwords using NLTK.\n",
        "* Word2Vec Model: We train a Word2Vec model on the preprocessed text. In this case, a sample corpus is used, but you can use a larger dataset for better predictions.\n",
        "* Next Word Prediction: The function predict_next_word() takes a context (a string of words) and computes the mean vector of the context words. It then finds the most similar words to this vector in the Word2Vec space, which are returned as the predicted next words."
      ],
      "metadata": {
        "id": "j9sfwwJ3jq5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gensim in Colab if not already installed\n",
        "!pip install gensim\n",
        "\n",
        "# Import necessary libraries\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "# Download the necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "bcdjTcysj9Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NO2JkagojDsl"
      },
      "outputs": [],
      "source": [
        "# Sample training corpus (You can replace this with a larger dataset)\n",
        "# For example, you can load a text file from Google Drive or online source.\n",
        "corpus = \"\"\"\n",
        "Machine learning is the study of computer algorithms that improve automatically through experience and by the use of data.\n",
        "It is seen as a part of artificial intelligence.\n",
        "Machine learning algorithms build a mathematical model based on sample data, known as training data,\n",
        "in order to make predictions or decisions without being explicitly programmed to do so.\n",
        "Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision,\n",
        "where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\n",
        "\"\"\"\n",
        "\n",
        "# Preprocess the text (lowercase, remove punctuation, stopwords)\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    return words\n",
        "\n",
        "# Preprocess the corpus\n",
        "preprocessed_corpus = preprocess_text(corpus)\n",
        "\n",
        "# Prepare data in the form required for Word2Vec (sentences split)\n",
        "sentences = [preprocessed_corpus]  # List of tokenized sentences\n",
        "\n",
        "# Train a Word2Vec model\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to predict the next word given a sequence of words\n",
        "def predict_next_word(model, context, top_n=3):\n",
        "    context_words = context.split()\n",
        "\n",
        "    # Check if all words in the context are in the model's vocabulary\n",
        "    if all(word in model.wv.index_to_key for word in context_words):\n",
        "        # Get the average vector of the context words\n",
        "        context_vector = np.mean([model.wv[word] for word in context_words], axis=0)\n",
        "\n",
        "        # Find the top_n most similar words to the context vector\n",
        "        similar_words = model.wv.similar_by_vector(context_vector, topn=top_n)\n",
        "        return [word for word, score in similar_words]\n",
        "    else:\n",
        "        return [\"One or more words in the context are not in the model vocabulary\"]\n",
        "\n",
        "# Example usage: Predicting the next word for a given context\n",
        "context = \"machine learning\"\n",
        "predicted_words = predict_next_word(model, context, top_n=3)\n",
        "print(f\"Context: '{context}'\")\n",
        "print(f\"Predicted next words: {predicted_words}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assigned task:\n",
        "Create a larger training corpus, and perform next word prediction and print the predicted next words."
      ],
      "metadata": {
        "id": "pFnZTgOgkdXu"
      }
    }
  ]
}