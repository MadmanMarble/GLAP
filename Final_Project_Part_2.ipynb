{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MadmanMarble/GLAP/blob/main/Final_Project_Part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#YOLOv8\n",
        "##A cutting-edge, state-of-the-art (SOTA) model that builds upon the success of previous YOLO versions\n",
        "See more here: [Ultralytics YOLOv8 site](https://github.com/ultralytics/ultralytics)\n",
        "\n",
        "Another resource is from [OpenCV](https://learnopencv.com/ultralytics-yolov8/)\n",
        "\n",
        "Features:\n",
        "* User-friendly API (Command Line + Python).\n",
        "* Faster and More Accurate.\n",
        "* Supports: Object Detection, Instance Segmentation, Image Classification.\n",
        "\n",
        "There are five models in each category of YOLOv8 models for detection, segmentation, and classification. YOLOv8 Nano is the fastest and smallest, while YOLOv8 Extra Large (YOLOv8x) is the most accurate yet the slowest among them.\n",
        "\n",
        "* YOLOv8n\n",
        "* YOLOv8s\n",
        "* YOLOv8m\n",
        "* YOLOv8l\n",
        "* YOLOv8x"
      ],
      "metadata": {
        "id": "fMc_L2DUG0RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary packages\n",
        "!pip install ultralytics\n",
        "!pip install opencv-python\n"
      ],
      "metadata": {
        "id": "RPpUBogrIMG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Upload image, perform object detection on image and count objects belonging to certain classes"
      ],
      "metadata": {
        "id": "HWuf7Z-VK49C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow  # for image display in Colab\n",
        "\n",
        "# Load the pre-trained YOLOv8 model\n",
        "model = YOLO('yolov8n.pt')  # You can use 'yolov8s.pt', 'yolov8m.pt', etc., for better accuracy but slower speed\n",
        "\n",
        "# Upload an image from your local machine\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded image path\n",
        "image_path = list(uploaded.keys())[0]\n",
        "\n",
        "# Perform object detection\n",
        "results = model(image_path)\n",
        "\n",
        "# Load image for display purposes\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# COCO class IDs: person (0), vehicles (car-2, bus-5, truck-7)\n",
        "car_class_ids = [2, 5, 7]  # COCO IDs for car, bus, truck (vehicles)\n",
        "person_class_id = 0  # COCO ID for person\n",
        "\n",
        "# Count cars and people\n",
        "car_count = 0\n",
        "person_count = 0\n",
        "\n",
        "for result in results:\n",
        "    for box in result.boxes:\n",
        "        class_id = int(box.cls)\n",
        "        if class_id == person_class_id:\n",
        "            person_count += 1\n",
        "        elif class_id in car_class_ids:\n",
        "            car_count += 1\n",
        "\n",
        "# Print the counts\n",
        "print(f'Number of people detected: {person_count}')\n",
        "print(f'Number of cars (vehicles) detected: {car_count}')\n",
        "\n",
        "# Annotate and display the image with detections\n",
        "annotated_image = results[0].plot()\n",
        "\n",
        "# Convert image from BGR (OpenCV) to RGB (Matplotlib)\n",
        "annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display the image in the notebook\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(annotated_image)\n",
        "plt.axis('off')  # Hide axis\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GnVsWuGh3sGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Assigned Task\n",
        "\n",
        "\n",
        "Compute the average x-coordinate and average y-coordinate of centers of all bounding boxes of objects from a certain class like \"cars\" in the image. Print those average numbers. Hint: the line of code below gives points on the bounding box:\n",
        "\n",
        "**x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()**\n",
        "\n"
      ],
      "metadata": {
        "id": "uKgxj-0RKNad"
      }
    }
  ]
}